{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1c5c3f",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d64fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install Conda package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70731fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b565e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "# to save in the Model Catalog\n",
    "from ads.model.generic_model import GenericModel\n",
    "from ads.model.model_metadata import MetadataCustomCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "931505c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !odsc conda init -b conda_environment_yolov5 -n frqap2zhtzbe -a resource_principal\n",
    "# !odsc conda publish -s tensorflow28_p38_gpu_v1 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7624937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see example payload\n",
    "f = open('input_json.json')\n",
    "payload = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40822a16",
   "metadata": {},
   "source": [
    "## **Download model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32cbf261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:25:06.514736: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 15:25:06.544210: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 15:25:07.243987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "class Reranker:\n",
    "    def __init__(self, model_id):\n",
    "        self.model_id = model_id\n",
    "        self.reranker = FlagReranker(self.model_id, use_fp16=True)\n",
    "\n",
    "    def predict(self, x):\n",
    "        # x is expected as a list of list of str\n",
    "        # [[\"x1\", \"x2\"]] -> y = [score12]\n",
    "        scores = self.reranker.compute_score(x)\n",
    "\n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    \n",
    "model = Reranker(model_id=\"BAAI/bge-reranker-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd48bd",
   "metadata": {},
   "source": [
    "## **Model artifacts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ea3cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n",
      "                                                                                                                                                                                                                                          ?, ?it/s]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: null\n",
       "artifact_dir:\n",
       "  /home/datascience/1_projects/re_ranking_juan/reranker_dir:\n",
       "  - - reranker.pkl\n",
       "    - score.py\n",
       "    - runtime.yaml\n",
       "    - test_json_output.json\n",
       "    - .model-ignore\n",
       "    - .ipynb_checkpoints\n",
       "    - .ipynb_checkpoints/score-checkpoint.py\n",
       "    - .ipynb_checkpoints/test_json_output-checkpoint.json\n",
       "framework: null\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "custom_conda = \"oci://conda_environment_yolov5@frqap2zhtzbe/conda_environments/gpu/TensorFlow 2.8 for GPU on Python 3.8/1.0/tensorflow28_p38_gpu_v1\"\n",
    "\n",
    "reranker_model = GenericModel(estimator=model, artifact_dir=\"./reranker_dir\")\n",
    "\n",
    "reranker_model.prepare(\n",
    "    reload=False,\n",
    "    inference_conda_env=custom_conda,\n",
    "    inference_python_version=\"3.9\",\n",
    "    model_file_name=\"reranker.pkl\",\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6684b",
   "metadata": {},
   "source": [
    "## **Define full script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc60d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./reranker_dir/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./reranker_dir/score.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import cloudpickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "\n",
    "#model_name = './reranker_dir/reranker.pkl'\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    class DummyModel:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "    return DummyModel()\n",
    "\n",
    "\n",
    "def predict(data, model=load_model()):\n",
    "    \n",
    "    model_name = 'reranker.pkl'\n",
    "    \n",
    "    with open(model_name, \"rb\") as file:\n",
    "        model = cloudpickle.load(file)\n",
    "\n",
    "    payload = data\n",
    "    \n",
    "    #get the origial question\n",
    "    original_question = payload['full_input']['original_question']\n",
    "    \n",
    "        ##create payload as expected by rerank model\n",
    "\n",
    "    payload_list = []\n",
    "    \n",
    "\n",
    "    for rowx in payload['full_input']['result']:\n",
    "\n",
    "        text = rowx['payload']['text']\n",
    "\n",
    "        payload_list.append([original_question, text])\n",
    "\n",
    "    #apply list to rerank model\n",
    "    rerank_predictions = model.predict(payload_list)\n",
    "\n",
    "    loopx = 0\n",
    "\n",
    "    #create output list\n",
    "    output_list = []\n",
    "    for rowyy in rerank_predictions:\n",
    "\n",
    "        #get the text\n",
    "        output_text = payload['full_input']['result'][loopx]['payload']['text']\n",
    "\n",
    "        #add score\n",
    "        output_list.append([output_text, rowyy])\n",
    "\n",
    "        loopx+=1\n",
    "\n",
    "    ########################\n",
    "    #load as dataframe and sort on score\n",
    "    df = pd.DataFrame(output_list, columns=[\"text\",\"score\"])\n",
    "    df = df.sort_values('score', ascending=False)\n",
    "\n",
    "    df_to_json = df.to_json(orient = 'records')\n",
    "    \n",
    "    return {'prediction': df_to_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af23d282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': '[{\"text\":\"\\\\nNo databases that run on-premises or in cloud environments today are 100% autonomous - but that is\\\\nthe goal toward which the industry is headed. To further the evolution of cloud databases toward this\\\\ntrue utility model, Oracle introduced the Autonomous Database, running on Oracle Database (version\\\\n18c and later) in the Oracle Cloud. Autonomous Database minimizes or eliminates human labor using\\\\nself-driving, self-securing and self-repairing functionality. Two key areas that comprise the self-\\\\nrepairing capabilities of the Autonomous Database are the Oracle Maximum Availability Architecture\",\"score\":4.0959706306},{\"text\":\"\\\\nor eliminate operational disruption.\\\\nWhat is the Autonomous Database Cloud?\\\\nAUTONOMOUS\\\\nDATABASE\\\\nORACLE\\\\n-\",\"score\":1.7019958496},{\"text\":\"\\\\nTable of Contents\\\\nIntroduction\\\\n4\\\\nWhat is an Autonomous Database?\\\\n4\",\"score\":1.257212162},{\"text\":\"\\\\nif you will. As a result, enterprises are unable to realize the full operational and financial benefits of the\\\\ncloud.\\\\nWHAT IS AN AUTONOMOUS DATABASE?\\\\nThere is understandably an element of confusion that arises when talking about automatic\\\\\" versus\\\\n\\'autonomous\\\\\" capabilities. A process for database backup, failover or resizing that can be\\\\naccomplished automatically is still not autonomous if a database administrator has to respond to an\",\"score\":1.245767951},{\"text\":\"\\\\nbehind corporate firewalls to meet data sovereignty or control requirements will soon be able to run\\\\nthe Autonomous Database on-premises. Oracle Exadata Cloud at Customer, an Oracle Public Cloud\\\\noffering, can be deployed on-premises, and delivers all of the capabilities of Autonomous Database\\\\nfrom within the enterprise\\'s data center.\\\\nThe Autonomous Database can be deployed in a hybrid cloud or all-cloud model; for example, when\\\\nmultiple databases are deployed for production and test environments or as primary and standby\",\"score\":1.1846054792}]'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9e36180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'reranker.pkl', '__pycache__', 'score.py', 'runtime.yaml', 'test_json_output.json', '.model-ignore']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test key</th>\n",
       "      <th>Test name</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runtime_env_path</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runtime_env_python</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runtime_path_exist</td>\n",
       "      <td>Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runtime_version</td>\n",
       "      <td>Check that field MODEL_ARTIFACT_VERSION is set to 3.0</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_yaml</td>\n",
       "      <td>Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score_load_model</td>\n",
       "      <td>Check that load_model() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>score_predict</td>\n",
       "      <td>Check that predict() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>score_predict_arg</td>\n",
       "      <td>Check that all other arguments in predict() are optional and have default values</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>score_predict_data</td>\n",
       "      <td>Check that the only required argument for predict() is named \"data\"</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>score_py</td>\n",
       "      <td>Check that the file \"score.py\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>score_syntax</td>\n",
       "      <td>Check for Python syntax errors</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test key  \\\n",
       "0     runtime_env_path   \n",
       "1   runtime_env_python   \n",
       "2   runtime_path_exist   \n",
       "3      runtime_version   \n",
       "4         runtime_yaml   \n",
       "5     score_load_model   \n",
       "6        score_predict   \n",
       "7    score_predict_arg   \n",
       "8   score_predict_data   \n",
       "9             score_py   \n",
       "10        score_syntax   \n",
       "\n",
       "                                                                                                Test name  \\\n",
       "0                                             Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set   \n",
       "1           Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher   \n",
       "2                             Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.   \n",
       "3                                                   Check that field MODEL_ARTIFACT_VERSION is set to 3.0   \n",
       "4   Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory   \n",
       "5                                                                      Check that load_model() is defined   \n",
       "6                                                                         Check that predict() is defined   \n",
       "7                        Check that all other arguments in predict() are optional and have default values   \n",
       "8                                     Check that the only required argument for predict() is named \"data\"   \n",
       "9       Check that the file \"score.py\" exists and is in the top level directory of the artifact directory   \n",
       "10                                                                         Check for Python syntax errors   \n",
       "\n",
       "    Result Message  \n",
       "0   Passed          \n",
       "1   Passed          \n",
       "2   Passed          \n",
       "3   Passed          \n",
       "4   Passed          \n",
       "5   Passed          \n",
       "6   Passed          \n",
       "7   Passed          \n",
       "8   Passed          \n",
       "9   Passed          \n",
       "10  Passed          "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranker_model.introspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd717561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reranker.pkl', 'score.py', 'runtime.yaml', 'test_json_output.json', '.model-ignore']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp1ius8yfy.zip has been successfully uploaded to oci://conda_environment_yolov5@frqap2zhtzbe/config/ocid1.datasciencemodel.oc1.eu-frankfurt-1.amaaaaaangencdyaz42hnqocq4hd7wdgm32iumzdx22a3rzkeexz3gmyimaq.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_29148/3289160801.py\", line 3, in <cell line: 3>\n",
      "    catalog_entry.id\n",
      "AttributeError: 'str' object has no attribute 'id'\n",
      "AttributeError: 'str' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "# Saving the model artifact to the model catalog. \n",
    "catalog_entry = reranker_model.save(display_name='rerank_v3', description='rerank_v3', timeout=600, bucket_uri=\"oci://conda_environment_yolov5@frqap2zhtzbe/config/\")\n",
    "catalog_entry.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e22949f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ocid1.datasciencemodel.oc1.eu-frankfurt-1.amaaaaaangencdyae7qnsghxrr56x7zht57qeriuvodzs5va3wxukpmeh3gq'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca54035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see example payload\n",
    "f = open('input_json.json')\n",
    "payload = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14dac987",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'full_input': {'original_question': 'When do you go home?',\n",
    "  'result': [{'id': 5469,\n",
    "    'version': 1,\n",
    "    'score': 0.7420407,\n",
    "    'payload': {'creation_date': '2024-01-29Z',\n",
    "     'document_name': 'autonomous-database-self-repairing-5116047 (1).pdf',\n",
    "     'hyperlink_url': '',\n",
    "     'page_number': 3,\n",
    "     'text': '\\nTable of Contents\\nIntroduction\\n4\\nWhat is an Autonomous Database?\\n4',\n",
    "     'type': 'pdf'},\n",
    "    'vector': None},\n",
    "   {'id': 5483,\n",
    "    'version': 2,\n",
    "    'score': 0.7236079,\n",
    "    'payload': {'creation_date': '2024-01-29Z',\n",
    "     'document_name': 'autonomous-database-self-repairing-5116047 (1).pdf',\n",
    "     'hyperlink_url': '',\n",
    "     'page_number': 5,\n",
    "     'text': '\\nor eliminate operational disruption.\\nWhat is the Autonomous Database Cloud?\\nAUTONOMOUS\\nDATABASE\\nORACLE\\n-',\n",
    "     'type': 'pdf'},\n",
    "    'vector': None},\n",
    "   {'id': 5542,\n",
    "    'version': 5,\n",
    "    'score': 0.67869973,\n",
    "    'payload': {'creation_date': '2024-01-29Z',\n",
    "     'document_name': 'autonomous-database-self-repairing-5116047 (1).pdf',\n",
    "     'hyperlink_url': '',\n",
    "     'page_number': 12,\n",
    "     'text': '\\nNo databases that run on-premises or in cloud environments today are 100% autonomous - but that is\\nthe goal toward which the industry is headed. To further the evolution of cloud databases toward this\\ntrue utility model, Oracle introduced the Autonomous Database, running on Oracle Database (version\\n18c and later) in the Oracle Cloud. Autonomous Database minimizes or eliminates human labor using\\nself-driving, self-securing and self-repairing functionality. Two key areas that comprise the self-\\nrepairing capabilities of the Autonomous Database are the Oracle Maximum Availability Architecture',\n",
    "     'type': 'pdf'},\n",
    "    'vector': None},\n",
    "   {'id': 5496,\n",
    "    'version': 2,\n",
    "    'score': 0.67500746,\n",
    "    'payload': {'creation_date': '2024-01-29Z',\n",
    "     'document_name': 'autonomous-database-self-repairing-5116047 (1).pdf',\n",
    "     'hyperlink_url': '',\n",
    "     'page_number': 6,\n",
    "     'text': \"\\nbehind corporate firewalls to meet data sovereignty or control requirements will soon be able to run\\nthe Autonomous Database on-premises. Oracle Exadata Cloud at Customer, an Oracle Public Cloud\\noffering, can be deployed on-premises, and delivers all of the capabilities of Autonomous Database\\nfrom within the enterprise's data center.\\nThe Autonomous Database can be deployed in a hybrid cloud or all-cloud model; for example, when\\nmultiple databases are deployed for production and test environments or as primary and standby\",\n",
    "     'type': 'pdf'},\n",
    "    'vector': None},\n",
    "   {'id': 5476,\n",
    "    'version': 1,\n",
    "    'score': 0.6721611,\n",
    "    'payload': {'creation_date': '2024-01-29Z',\n",
    "     'document_name': 'autonomous-database-self-repairing-5116047 (1).pdf',\n",
    "     'hyperlink_url': '',\n",
    "     'page_number': 4,\n",
    "     'text': '\\nif you will. As a result, enterprises are unable to realize the full operational and financial benefits of the\\ncloud.\\nWHAT IS AN AUTONOMOUS DATABASE?\\nThere is understandably an element of confusion that arises when talking about automatic\" versus\\n\\'autonomous\" capabilities. A process for database backup, failover or resizing that can be\\naccomplished automatically is still not autonomous if a database administrator has to respond to an',\n",
    "     'type': 'pdf'},\n",
    "    'vector': None}],\n",
    "  'status': 'ok',\n",
    "  'time': 0.00130104}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cb067a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'prediction': '[{\"text\":\"\\\\nNo databases that run on-premises or in cloud environments today are 100% autonomous - but that is\\\\nthe goal toward which the industry is headed. To further the evolution of cloud databases toward this\\\\ntrue utility model, Oracle introduced the Autonomous Database, running on Oracle Database (version\\\\n18c and later) in the Oracle Cloud. Autonomous Database minimizes or eliminates human labor using\\\\nself-driving, self-securing and self-repairing functionality. Two key areas that comprise the self-\\\\nrepairing capabilities of the Autonomous Database are the Oracle Maximum Availability Architecture\",\"score\":-8.0765218735},{\"text\":\"\\\\nbehind corporate firewalls to meet data sovereignty or control requirements will soon be able to run\\\\nthe Autonomous Database on-premises. Oracle Exadata Cloud at Customer, an Oracle Public Cloud\\\\noffering, can be deployed on-premises, and delivers all of the capabilities of Autonomous Database\\\\nfrom within the enterprise\\'s data center.\\\\nThe Autonomous Database can be deployed in a hybrid cloud or all-cloud model; for example, when\\\\nmultiple databases are deployed for production and test environments or as primary and standby\",\"score\":-9.0334005356},{\"text\":\"\\\\nif you will. As a result, enterprises are unable to realize the full operational and financial benefits of the\\\\ncloud.\\\\nWHAT IS AN AUTONOMOUS DATABASE?\\\\nThere is understandably an element of confusion that arises when talking about automatic\\\\\" versus\\\\n\\'autonomous\\\\\" capabilities. A process for database backup, failover or resizing that can be\\\\naccomplished automatically is still not autonomous if a database administrator has to respond to an\",\"score\":-9.4226465225},{\"text\":\"\\\\nor eliminate operational disruption.\\\\nWhat is the Autonomous Database Cloud?\\\\nAUTONOMOUS\\\\nDATABASE\\\\nORACLE\\\\n-\",\"score\":-9.4815664291},{\"text\":\"\\\\nTable of Contents\\\\nIntroduction\\\\n4\\\\nWhat is an Autonomous Database?\\\\n4\",\"score\":-9.4821510315}]'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer\n",
    "import json\n",
    "\n",
    "uri = f\"https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyaeibpd24ie2ap7lmyxeiatfntl6qpoy3nejefqxvtpa5a/predict\"\n",
    "\n",
    "\n",
    "config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "auth = Signer(\n",
    "        tenancy=config['tenancy'],\n",
    "        user=config['user'],\n",
    "        fingerprint=config['fingerprint'],\n",
    "        private_key_file_location=config['key_file'],\n",
    "        pass_phrase=config['pass_phrase'])\n",
    "\n",
    "\n",
    "#POST request to the model\n",
    "response = requests.post(uri, json=payload, auth=auth)\n",
    "print(response)\n",
    "full_response = (json.loads(response.content))\n",
    "print(full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c8718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebc331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e6db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b307b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111f3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
